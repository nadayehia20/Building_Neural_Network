{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep-neural-network_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jlASql-trw2",
        "outputId": "ae720d49-2280-4ad6-f947-fa08e7d2d41b"
      },
      "source": [
        "    from google.colab import drive\r\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVS0EOEOQ423"
      },
      "source": [
        "\r\n",
        "class NeuralNetwork():\r\n",
        "  \r\n",
        "\r\n",
        "\r\n",
        "    def __init__(self, loss='crossentropy', classifier='categorical', metric='accuracy', learning_rate=.04):\r\n",
        "        ALLOWED_LOSSES = ['crossentropy']\r\n",
        "        ALLOWED_CLASSIFIERS = ['binary', 'categorical']\r\n",
        "        ALLOWED_METRICS = ['accuracy','percision','recall','f1 score']\r\n",
        "\r\n",
        "        self.W = [np.NaN]\r\n",
        "        self.b = [np.NaN]\r\n",
        "        self.Z = [np.NaN]\r\n",
        "        self.A = [np.NaN]\r\n",
        "\r\n",
        "        self.layer_activations = [None]\r\n",
        "        self.layer_units = [0]\r\n",
        "        self.layer_initializers = [None]\r\n",
        "\r\n",
        "        self.loss_function = loss\r\n",
        "        self.classifier = classifier\r\n",
        "        self.metric = metric\r\n",
        "        self.loss_history = [np.NaN]\r\n",
        "        self.metric_history = [np.NaN]\r\n",
        "        self.loss = 0.\r\n",
        "        self.learning_rate = learning_rate\r\n",
        "\r\n",
        "    def activation_func(self, z, activation=None, return_derivative=False):\r\n",
        "\r\n",
        "        if activation == 'sigmoid':\r\n",
        "            s = 1/(1 + np.exp(-z))\r\n",
        "            if return_derivative:\r\n",
        "                return s*(1 - s)\r\n",
        "\r\n",
        "        elif activation == 'tanh':\r\n",
        "            s = np.tanh(z)\r\n",
        "            if return_derivative:\r\n",
        "                return 1 - s**2\r\n",
        "\r\n",
        "        elif activation == 'reLU':\r\n",
        "            s = np.maximum(z, 0)\r\n",
        "            if return_derivative:\r\n",
        "                return (s > 0)*s\r\n",
        "\r\n",
        "        elif activation == 'leakyrelu':\r\n",
        "            s = np.where(z > 0, z, z * 0.01)\r\n",
        "            if return_derivative:\r\n",
        "              s = np.ones_like(z)\r\n",
        "              s[z < 0] = alpha\r\n",
        "              return s\r\n",
        "\r\n",
        "        elif activation == 'softmax':\r\n",
        "            max_z = np.max(z, axis=0, keepdims=True)\r\n",
        "            s = np.exp(z - max_z)\r\n",
        "            norm = np.sum(s, axis=0, keepdims=True)\r\n",
        "            s = s/norm\r\n",
        "            if return_derivative:\r\n",
        "                return s*(1-s)\r\n",
        "\r\n",
        "        return s\r\n",
        "\r\n",
        "    def forward_propagate(self):\r\n",
        "        num_layers = len(self.layer_units) - 1\r\n",
        "        for l in range(1, num_layers+1):\r\n",
        "            self.Z[l] = np.dot(self.W[l], self.A[l-1]) + self.b[l]\r\n",
        "            self.A[l] = self.activation_func(self.Z[l], activation=self.layer_activations[l])\r\n",
        "\r\n",
        "    def calculate_output_dZ(self, actual):\r\n",
        "\r\n",
        "        if self.classifier=='categorical':\r\n",
        "            if self.loss_function=='crossentropy':\r\n",
        "                return -actual*(1 - self.A[-1])\r\n",
        "        elif self.classifier=='binary':\r\n",
        "            if self.loss_function=='crossentropy':\r\n",
        "                return -actual + self.A[-1]\r\n",
        "\r\n",
        "    def backward_propagate(self, actual):\r\n",
        "\r\n",
        "        m = actual.shape[-1]\r\n",
        "        num_layers = len(self.layer_units) - 1\r\n",
        "\r\n",
        "        # Iterate from layer L-1 to layer 1\r\n",
        "        for l in range(num_layers, 0, -1):\r\n",
        "            if l == num_layers:\r\n",
        "                dZ = self.calculate_output_dZ(actual)\r\n",
        "            else:\r\n",
        "                g = self.activation_func(self.Z[l], activation=self.layer_activations[l], return_derivative=True)\r\n",
        "                dZ = g*np.dot(np.transpose(self.W[l+1]), dZ) \r\n",
        "\r\n",
        "            dW = (1/m)*np.dot(dZ, np.transpose(self.A[l-1]))\r\n",
        "            dB = (1/m)*np.sum(dZ, axis=1, keepdims=True)\r\n",
        "\r\n",
        "            # Update parameters\r\n",
        "            self.W[l] = self.W[l] - self.learning_rate*dW\r\n",
        "            self.b[l] = self.b[l] - self.learning_rate*dB\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def calculate_loss(self, actual):\r\n",
        "\r\n",
        "        m = actual.shape[-1]\r\n",
        "        predicted = self.A[-1]\r\n",
        "\r\n",
        "\r\n",
        "        if self.loss_function == 'crossentropy' and self.classifier == 'binary':\r\n",
        "            loss_vector = -actual*np.log(predicted) - (1 - actual)*np.log(1-predicted)\r\n",
        "        elif self.loss_function == 'crossentropy' and self.classifier == 'categorical':\r\n",
        "            loss_vector = np.sum(-actual*np.log(predicted), axis=0, keepdims=True)\r\n",
        "\r\n",
        "        self.loss = (1/m)*np.sum(loss_vector)\r\n",
        "        self.loss_history.append(self.loss)\r\n",
        "\r\n",
        "\r\n",
        "    def initialize_params(self, X_input):\r\n",
        "\r\n",
        "        self.layer_units[0] = X_input.shape[0]\r\n",
        "        m = X_input.shape[-1]\r\n",
        "\r\n",
        "        num_layers = len(self.layer_units) - 1\r\n",
        "        for l in range(1, num_layers+1):\r\n",
        "            n_l = self.layer_units[l]\r\n",
        "            n_prev = self.layer_units[l-1]\r\n",
        "\r\n",
        "            if self.layer_initializers[l] == 'zeros':\r\n",
        "                self.W.append(np.zeros(shape=(n_l, n_prev), dtype=np.float32))\r\n",
        "                self.b.append(np.zeros(shape=(n_l, 1), dtype=np.float32))\r\n",
        "            elif self.layer_initializers[l] == 'random':\r\n",
        "                self.W.append(np.random.rand(n_l, n_prev).astype(np.float32))\r\n",
        "                self.b.append(np.random.rand(n_l, 1).astype(np.float32))\r\n",
        "\r\n",
        "            elif self.layer_initializers[l] == 'xavier':\r\n",
        "                stddev = np.sqrt(1/n_prev)\r\n",
        "                self.W.append(stddev*np.random.randn(n_l, n_prev).astype(np.float32))\r\n",
        "                self.b.append(stddev*np.random.randn(n_l, 1).astype(np.float32))\r\n",
        "            else:\r\n",
        "                return False\r\n",
        "            self.Z.append(np.zeros(shape=(n_l, m), dtype=np.float32))\r\n",
        "            self.A.append(np.zeros(shape=(n_l, m), dtype=np.float32))\r\n",
        "\r\n",
        "\r\n",
        "    def add_layer(self, units, activation='tanh', initializer='xavier'):\r\n",
        "\r\n",
        "        self.layer_units.append(units)\r\n",
        "        self.layer_activations.append(activation)\r\n",
        "        self.layer_initializers.append(initializer)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def train(self, x_train, y_train, iterations=1):\r\n",
        "\r\n",
        "        if self.classifier == 'categorical':\r\n",
        "            if y_train.ndim == 1:\r\n",
        "                one_hot_array = np.zeros(shape=(y_train.max()+1, y_train.size))\r\n",
        "                one_hot_array[y_train, np.arange(y_train.size)] = 1\r\n",
        "                y_train = one_hot_array\r\n",
        "        if self.classifier == 'binary':\r\n",
        "            if y_train.ndim == 1:\r\n",
        "                y_train = np.expand_dims(y_train, axis=0)\r\n",
        "\r\n",
        "\r\n",
        "        self.A[0] = x_train\r\n",
        "        self.initialize_params(x_train)\r\n",
        "\r\n",
        "        print('Training neural network.')\r\n",
        "        for i in range(iterations):\r\n",
        "\r\n",
        "            self.forward_propagate()\r\n",
        "            self.calculate_loss(y_train)\r\n",
        "            self.backward_propagate(y_train)\r\n",
        "\r\n",
        "            print_step_size = int(iterations/100) if iterations > 100 else 1\r\n",
        "            if i % print_step_size == 0:\r\n",
        "                print('At iteration {}, J = {}'.format(i, self.loss))\r\n",
        "\r\n",
        "    def test(self, x_test, y_test):\r\n",
        "\r\n",
        "        if y_test.ndim == 1:\r\n",
        "            y_test = np.expand_dims(y_test, axis=0)\r\n",
        "\r\n",
        "        if self.classifier == 'categorical':\r\n",
        "            if y_test.ndim == 1:\r\n",
        "                one_hot_array = np.zeros(shape=(y_test.max()+1, y_test.size))\r\n",
        "                one_hot_array[y_test, np.arange(y_test.size)] = 1\r\n",
        "                y_test = one_hot_array\r\n",
        "        if self.classifier == 'binary':\r\n",
        "            if y_test.ndim == 1:\r\n",
        "                y_test = np.expand_dims(y_test, axis=0)\r\n",
        "\r\n",
        "        self.A[0] = x_test\r\n",
        "        self.forward_propagate()\r\n",
        "        return self.A[-1]\r\n",
        "\r\n",
        "\r\n",
        "    def evaluation_matrix(self, prediction, actual):\r\n",
        "\r\n",
        "        \r\n",
        "        prediction_onehot = np.zeros_like(prediction)\r\n",
        "        prediction_onehot[prediction.argmax(0), np.arange(prediction.shape[1])] = 1\r\n",
        "\r\n",
        "        predictedClass= prediction_onehot.T \r\n",
        "        one_dim_predicted_class=[]\r\n",
        "        for i in range(len(predictedClass)):\r\n",
        "            one_dim_predicted_class.append(np.argmax(predictedClass[i]))\r\n",
        "        \r\n",
        "        actual_list=actual.tolist()\r\n",
        "        sum=0\r\n",
        "        for i in range(len(actual_list)):\r\n",
        "          if actual_list[i]==one_dim_predicted_class[i]:\r\n",
        "              sum+=1\r\n",
        "        print(\"accuracy = \", (sum/ len(actual_list))*100)\r\n",
        "        currentDataClass=actual_list\r\n",
        "        classes = set(currentDataClass)\r\n",
        "        number_of_classes = prediction.shape[0]\r\n",
        "        y_actu = pd.Series(currentDataClass)\r\n",
        "        y_pred = pd.Series(one_dim_predicted_class)\r\n",
        "        conf_matrix = pd.crosstab(y_actu, y_pred)\r\n",
        "        cm = conf_matrix.values\r\n",
        "\r\n",
        "        true_pos = np.diag(cm)\r\n",
        "        false_pos = np.sum(cm, axis=0) - true_pos\r\n",
        "        false_neg = np.sum(cm, axis=1) - true_pos\r\n",
        "        print(true_pos.sum(),false_pos.sum(), false_neg.sum())\r\n",
        "\r\n",
        "        precision = true_pos.sum()/ (true_pos.sum() + false_pos.sum()+0.00001)\r\n",
        "        recall = true_pos.sum() / (true_pos.sum() + false_neg.sum())\r\n",
        "        f1_score= 2*( (precision*recall) / (precision+recall) )\r\n",
        "        print(\"precision = \",precision*100)\r\n",
        "        print(\"f1_score = \",f1_score*100)\r\n",
        "        print(\"recall = \",recall*100)\r\n",
        "\r\n",
        "\r\n",
        "    def visualize(self):\r\n",
        "      import matplotlib.pyplot as plt\r\n",
        "      plt.plot(self.loss_history)\r\n",
        "      plt.title('Loss Vs iterations')\r\n",
        "      plt.xlabel('iterations')\r\n",
        "      plt.ylabel('L')\r\n",
        "      plt.show()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6jxaPMpsAWH"
      },
      "source": [
        "class Data():\r\n",
        "      def shuffle_split_data(self,X,y,train_size=0.7):\r\n",
        "        arr_rand = np.random.rand(X.shape[0])\r\n",
        "        split = arr_rand < np.percentile(arr_rand, train_size*100)\r\n",
        "        X_train =  np.array(X[split]).T\r\n",
        "        y_train = np.array(y[split]).ravel()\r\n",
        "        X_test = np.array( X[~split]).T\r\n",
        "        y_test = np.array(y[~split]).ravel()\r\n",
        "        return X_train, y_train, X_test, y_test\r\n",
        "\r\n",
        "      def load_data(self,path,label):\r\n",
        "        data=pd.read_csv(path)\r\n",
        "        Y = data[[label]]\r\n",
        "        data.drop([label], inplace=True, axis=1)\r\n",
        "        X=data\r\n",
        "        return self.shuffle_split_data(X,Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcpp1_Kptje1"
      },
      "source": [
        "class utils():\r\n",
        "  def load_model(self,filename):\r\n",
        "    import pickle \r\n",
        "    loaded_model = pickle.load(open(filename, 'rb'))\r\n",
        "    return loaded_model\r\n",
        "\r\n",
        "  def save_model(self,nn,filename):\r\n",
        "    import pickle \r\n",
        "    pickle.dump(nn, open(filename, 'wb'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aR8-2Fv8aVry",
        "outputId": "82461704-b27f-4d38-fc5e-2ab9ea79e349"
      },
      "source": [
        "if __name__ == '__main__':\r\n",
        "    import numpy as np\r\n",
        "    import pandas as pd\r\n",
        "    # Initialize the NN and build the layers\r\n",
        "    nn = NeuralNetwork(loss='crossentropy', classifier='categorical', learning_rate=.02, metric='accuracy')\r\n",
        "    nn.add_layer(units=20, activation='tanh', initializer='xavier')\r\n",
        "    nn.add_layer(units=40, activation='tanh', initializer='xavier')\r\n",
        "    nn.add_layer(units=10, activation='softmax', initializer='xavier')\r\n",
        "    data_loader=Data()\r\n",
        "    path='/content/drive/MyDrive/datasets/train.csv'\r\n",
        "    label='label'\r\n",
        "    x_train, y_train, x_test, y_test=data_loader.load_data(path,label)\r\n",
        "    nn.train(x_train=x_train, y_train=y_train, iterations=50)\r\n",
        "    nn.visualize()\r\n",
        "    # Test NN on our test set\r\n",
        "    prediction = nn.test(x_test=x_test, y_test=y_test)\r\n",
        "    nn.evaluation_matrix(prediction , y_test)\r\n",
        "    util=utils()\r\n",
        "    filename = 'final_model2.sav'\r\n",
        "    util.save_model(nn,filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training neural network.\n",
            "At iteration 0, J = 2.4808302946838623\n",
            "At iteration 1, J = 2.4108455796533166\n",
            "At iteration 2, J = 2.3719569035803465\n",
            "At iteration 3, J = 2.3317656886168687\n",
            "At iteration 4, J = 2.295038871792033\n",
            "At iteration 5, J = 2.259310426279142\n",
            "At iteration 6, J = 2.2209015202438467\n",
            "At iteration 7, J = 2.1916729211236454\n",
            "At iteration 8, J = 2.1667405521642142\n",
            "At iteration 9, J = 2.1458170624828266\n",
            "At iteration 10, J = 2.123119359040292\n",
            "At iteration 11, J = 2.1055316590308717\n",
            "At iteration 12, J = 2.08210624180616\n",
            "At iteration 13, J = 2.0673951310204313\n",
            "At iteration 14, J = 2.051421320345106\n",
            "At iteration 15, J = 2.036378836486892\n",
            "At iteration 16, J = 2.022381606670033\n",
            "At iteration 17, J = 2.0105593962531136\n",
            "At iteration 18, J = 1.9950982854361778\n",
            "At iteration 19, J = 1.988422820040294\n",
            "At iteration 20, J = 1.9745299827336502\n",
            "At iteration 21, J = 1.9695098392705095\n",
            "At iteration 22, J = 1.9550195659151994\n",
            "At iteration 23, J = 1.9438356659713256\n",
            "At iteration 24, J = 1.936983429109143\n",
            "At iteration 25, J = 1.9304952529438937\n",
            "At iteration 26, J = 1.9205399904144722\n",
            "At iteration 27, J = 1.9174578409565088\n",
            "At iteration 28, J = 1.9092252704814463\n",
            "At iteration 29, J = 1.9020209880492382\n",
            "At iteration 30, J = 1.8939128638174485\n",
            "At iteration 31, J = 1.8876558776036974\n",
            "At iteration 32, J = 1.8798305978086314\n",
            "At iteration 33, J = 1.8757421100273461\n",
            "At iteration 34, J = 1.8696171591452762\n",
            "At iteration 35, J = 1.8651579022117586\n",
            "At iteration 36, J = 1.8596257484087821\n",
            "At iteration 37, J = 1.8514877056474313\n",
            "At iteration 38, J = 1.8489149432224126\n",
            "At iteration 39, J = 1.8399728089713647\n",
            "At iteration 40, J = 1.8410923854570374\n",
            "At iteration 41, J = 1.8293535071685283\n",
            "At iteration 42, J = 1.8261869531689072\n",
            "At iteration 43, J = 1.8207379072492134\n",
            "At iteration 44, J = 1.8164731545415589\n",
            "At iteration 45, J = 1.80998909284302\n",
            "At iteration 46, J = 1.812892092461435\n",
            "At iteration 47, J = 1.802413001588818\n",
            "At iteration 48, J = 1.8027122342118207\n",
            "At iteration 49, J = 1.7954084418556808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy =  39.58730158730159\n",
            "4988 7612 7612\n",
            "precision =  39.587301555883094\n",
            "f1_score =  39.58730157159235\n",
            "recall =  39.58730158730159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haw22I3gzbK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce4e876-ce51-4bd7-e8da-3100c7553d1f"
      },
      "source": [
        "    \r\n",
        "    x=util.load_model(filename)\r\n",
        "    pred=x.test(x_test,y_test)\r\n",
        "    x.evaluation_matrix(pred,y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy =  39.58730158730159\n",
            "4988 7612 7612\n",
            "precision =  39.587301555883094\n",
            "f1_score =  39.58730157159235\n",
            "recall =  39.58730158730159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNC_1fsZ3Jgf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
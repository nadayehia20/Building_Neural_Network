{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep-neural-network_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jlASql-trw2",
        "outputId": "1662ad5c-66e6-432b-f52a-2b467394a4af"
      },
      "source": [
        "    from google.colab import drive\r\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVS0EOEOQ423"
      },
      "source": [
        "\r\n",
        "class NeuralNetwork():\r\n",
        "  \r\n",
        "\r\n",
        "\r\n",
        "    def __init__(self, loss='crossentropy', classifier='categorical', metric='accuracy', learning_rate=.04):\r\n",
        "        import numpy as np\r\n",
        "        import pandas as pd\r\n",
        "        ALLOWED_LOSSES = ['crossentropy']\r\n",
        "        ALLOWED_CLASSIFIERS = ['binary', 'categorical']\r\n",
        "        ALLOWED_METRICS = ['accuracy','percision','recall','f1 score']\r\n",
        "\r\n",
        "        self.W = [np.NaN]\r\n",
        "        self.b = [np.NaN]\r\n",
        "        self.Z = [np.NaN]\r\n",
        "        self.A = [np.NaN]\r\n",
        "\r\n",
        "        self.layer_activations = [None]\r\n",
        "        self.layer_units = [0]\r\n",
        "        self.layer_initializers = [None]\r\n",
        "\r\n",
        "        self.loss_function = loss\r\n",
        "        self.classifier = classifier\r\n",
        "        self.metric = metric\r\n",
        "        self.loss_history = [np.NaN]\r\n",
        "        self.metric_history = [np.NaN]\r\n",
        "        self.loss = 0.\r\n",
        "        self.learning_rate = learning_rate\r\n",
        "\r\n",
        "    def activation_func(self, z, activation=None, return_derivative=False):\r\n",
        "        import numpy as np\r\n",
        "        if activation == 'sigmoid':\r\n",
        "            s = 1/(1 + np.exp(-z))\r\n",
        "            if return_derivative:\r\n",
        "                return s*(1 - s)\r\n",
        "\r\n",
        "        elif activation == 'tanh':\r\n",
        "            s = np.tanh(z)\r\n",
        "            if return_derivative:\r\n",
        "                return 1 - s**2\r\n",
        "\r\n",
        "        elif activation == 'reLU':\r\n",
        "            s = np.maximum(z, 0)\r\n",
        "            if return_derivative:\r\n",
        "                return (s > 0)*s\r\n",
        "\r\n",
        "        elif activation == 'leakyrelu':\r\n",
        "            s = np.where(z > 0, z, z * 0.01)\r\n",
        "            if return_derivative:\r\n",
        "              s = np.ones_like(z)\r\n",
        "              s[z < 0] = alpha\r\n",
        "              return s\r\n",
        "\r\n",
        "        elif activation == 'softmax':\r\n",
        "            max_z = np.max(z, axis=0, keepdims=True)\r\n",
        "            s = np.exp(z - max_z)\r\n",
        "            norm = np.sum(s, axis=0, keepdims=True)\r\n",
        "            s = s/norm\r\n",
        "            if return_derivative:\r\n",
        "                return s*(1-s)\r\n",
        "\r\n",
        "        return s\r\n",
        "\r\n",
        "    def forward_propagate(self): \r\n",
        "        import numpy as np     \r\n",
        "        num_layers = len(self.layer_units) - 1    #get the number of layers except output layer \r\n",
        "        for l in range(1, num_layers+1):\r\n",
        "            self.Z[l] = np.dot(self.W[l], self.A[l-1]) + self.b[l]\r\n",
        "            self.A[l] = self.activation_func(self.Z[l], activation=self.layer_activations[l])\r\n",
        "\r\n",
        "    def calculate_output_dZ(self, actual):\r\n",
        "        import numpy as np\r\n",
        "        if self.classifier=='categorical':\r\n",
        "            if self.loss_function=='crossentropy':\r\n",
        "                return -actual*(1 - self.A[-1])\r\n",
        "        elif self.classifier=='binary':\r\n",
        "            if self.loss_function=='crossentropy':\r\n",
        "                return -actual + self.A[-1]\r\n",
        "\r\n",
        "    def backward_propagate(self, actual):\r\n",
        "        import numpy as np\r\n",
        "        m = actual.shape[-1]\r\n",
        "        num_layers = len(self.layer_units) - 1\r\n",
        "\r\n",
        "        # Iterate from layer L-1 to layer 1\r\n",
        "        for l in range(num_layers, 0, -1):\r\n",
        "            if l == num_layers:\r\n",
        "                dZ = self.calculate_output_dZ(actual)\r\n",
        "            else:\r\n",
        "                g = self.activation_func(self.Z[l], activation=self.layer_activations[l], return_derivative=True)\r\n",
        "                dZ = g*np.dot(np.transpose(self.W[l+1]), dZ) \r\n",
        "\r\n",
        "            dW = (1/m)*np.dot(dZ, np.transpose(self.A[l-1]))\r\n",
        "            dB = (1/m)*np.sum(dZ, axis=1, keepdims=True)\r\n",
        "\r\n",
        "            # Update parameters\r\n",
        "            self.W[l] = self.W[l] - self.learning_rate*dW\r\n",
        "            self.b[l] = self.b[l] - self.learning_rate*dB\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def calculate_loss(self, actual):\r\n",
        "        import numpy as np\r\n",
        "        m = actual.shape[-1]\r\n",
        "        predicted = self.A[-1]\r\n",
        "\r\n",
        "\r\n",
        "        if self.loss_function == 'crossentropy' and self.classifier == 'binary':\r\n",
        "            loss_vector = -actual*np.log(predicted) - (1 - actual)*np.log(1-predicted)\r\n",
        "        elif self.loss_function == 'crossentropy' and self.classifier == 'categorical':\r\n",
        "            loss_vector = np.sum(-actual*np.log(predicted), axis=0, keepdims=True)\r\n",
        "\r\n",
        "        self.loss = (1/m)*np.sum(loss_vector)\r\n",
        "        self.loss_history.append(self.loss)\r\n",
        "\r\n",
        "\r\n",
        "    def initialize_params(self, X_input):\r\n",
        "        import numpy as np\r\n",
        "\r\n",
        "        self.layer_units[0] = X_input.shape[0]\r\n",
        "        m = X_input.shape[-1]\r\n",
        "\r\n",
        "        num_layers = len(self.layer_units) - 1\r\n",
        "        for l in range(1, num_layers+1):\r\n",
        "            n_l = self.layer_units[l]\r\n",
        "            n_prev = self.layer_units[l-1]\r\n",
        "\r\n",
        "            if self.layer_initializers[l] == 'zeros':\r\n",
        "                self.W.append(np.zeros(shape=(n_l, n_prev), dtype=np.float32))\r\n",
        "                self.b.append(np.zeros(shape=(n_l, 1), dtype=np.float32))\r\n",
        "            elif self.layer_initializers[l] == 'random':\r\n",
        "                self.W.append(np.random.rand(n_l, n_prev).astype(np.float32))\r\n",
        "                self.b.append(np.random.rand(n_l, 1).astype(np.float32))\r\n",
        "\r\n",
        "            elif self.layer_initializers[l] == 'xavier':\r\n",
        "                stddev = np.sqrt(1/n_prev)\r\n",
        "                self.W.append(stddev*np.random.randn(n_l, n_prev).astype(np.float32))\r\n",
        "                self.b.append(stddev*np.random.randn(n_l, 1).astype(np.float32))\r\n",
        "            else:\r\n",
        "                return False\r\n",
        "            self.Z.append(np.zeros(shape=(n_l, m), dtype=np.float32))\r\n",
        "            self.A.append(np.zeros(shape=(n_l, m), dtype=np.float32))\r\n",
        "\r\n",
        "\r\n",
        "    def add_layer(self, units, activation='tanh', initializer='xavier'):\r\n",
        "\r\n",
        "        self.layer_units.append(units)\r\n",
        "        self.layer_activations.append(activation)\r\n",
        "        self.layer_initializers.append(initializer)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def train(self, x_train, y_train, iterations):\r\n",
        "        import numpy as np\r\n",
        "\r\n",
        "        if self.classifier == 'categorical':\r\n",
        "            if y_train.ndim == 1:\r\n",
        "                one_hot_array = np.zeros(shape=(y_train.max()+1, y_train.size))\r\n",
        "                one_hot_array[y_train, np.arange(y_train.size)] = 1\r\n",
        "                y_train = one_hot_array\r\n",
        "        if self.classifier == 'binary':\r\n",
        "            if y_train.ndim == 1:\r\n",
        "                y_train = np.expand_dims(y_train, axis=0)\r\n",
        "\r\n",
        "\r\n",
        "        self.A[0] = x_train\r\n",
        "        self.initialize_params(x_train)\r\n",
        "\r\n",
        "        print('Training neural network.')\r\n",
        "        for i in range(iterations):\r\n",
        "\r\n",
        "            self.forward_propagate()\r\n",
        "            self.calculate_loss(y_train)\r\n",
        "            self.backward_propagate(y_train)\r\n",
        "\r\n",
        "            print_step_size = int(iterations/100) if iterations > 100 else 1\r\n",
        "            if i % print_step_size == 0:\r\n",
        "                print('At iteration {}, J = {}'.format(i, self.loss))\r\n",
        "\r\n",
        "    def test(self, x_test, y_test):\r\n",
        "        import numpy as np\r\n",
        "        if y_test.ndim == 1:\r\n",
        "            y_test = np.expand_dims(y_test, axis=0)\r\n",
        "\r\n",
        "        if self.classifier == 'categorical':\r\n",
        "            if y_test.ndim == 1:\r\n",
        "                one_hot_array = np.zeros(shape=(y_test.max()+1, y_test.size))\r\n",
        "                one_hot_array[y_test, np.arange(y_test.size)] = 1\r\n",
        "                y_test = one_hot_array\r\n",
        "        if self.classifier == 'binary':\r\n",
        "            if y_test.ndim == 1:\r\n",
        "                y_test = np.expand_dims(y_test, axis=0)\r\n",
        "\r\n",
        "        self.A[0] = x_test\r\n",
        "        self.forward_propagate()\r\n",
        "        return self.A[-1]\r\n",
        "\r\n",
        "\r\n",
        "    def evaluation_metric(self, prediction, actual): #calculate accuracy,precision,recall,f1_score\r\n",
        "\r\n",
        "        import numpy as np\r\n",
        "        import pandas as pd\r\n",
        "\r\n",
        "        prediction_onehot = np.zeros_like(prediction) #array of zeros with same shape of prediction \r\n",
        "        prediction_onehot[prediction.argmax(0), np.arange(prediction.shape[1])] = 1 #all equal zero except maximum =1 [0 0 0 1 0 0 0]\r\n",
        "\r\n",
        "\r\n",
        "        predictedClass= prediction_onehot.T #transpose one hot code\r\n",
        "        one_dim_predicted_class=[]\r\n",
        "        for i in range(len(predictedClass)):\r\n",
        "            one_dim_predicted_class.append(np.argmax(predictedClass[i])) #convert one hot code to 1D array (returns the index of the max value)\r\n",
        "        \r\n",
        "        actual_list=actual.tolist() #convert the array to list\r\n",
        "        sum=0\r\n",
        "        for i in range(len(actual_list)):\r\n",
        "          if actual_list[i]==one_dim_predicted_class[i]:\r\n",
        "              sum+=1 #for every true prediction\r\n",
        "        print(\"accuracy = \", (sum/ len(actual_list))*100) #calculate the accuracy (true predictions/total no. of examples)\r\n",
        "        currentDataClass=actual_list\r\n",
        "        classes = set(currentDataClass) #get the available labels without repetition \r\n",
        "\r\n",
        "        y_actu = pd.Series(currentDataClass) #construct a series of true labels\r\n",
        "        y_pred = pd.Series(one_dim_predicted_class) #construct a series of predictions\r\n",
        "        conf_matrix = pd.crosstab(y_actu, y_pred) #construct confusion matrix\r\n",
        "        cm = conf_matrix.values\r\n",
        "\r\n",
        "        true_pos = np.diag(cm) #get true positives\r\n",
        "        false_pos = np.sum(cm, axis=0) - true_pos #get false positives\r\n",
        "        false_neg = np.sum(cm, axis=1) - true_pos #get false negatives\r\n",
        "\r\n",
        "        precision = true_pos.sum()/ (true_pos.sum() + false_pos.sum()+0.00001) #P=TP/TP+FP\r\n",
        "        recall = true_pos.sum() / (true_pos.sum() + false_neg.sum()) #R=TP/TP+FN\r\n",
        "        f1_score= 2*( (precision*recall) / (precision+recall) )  #F1Score=P*R/P+R\r\n",
        "        print(\"precision = \",precision*100)\r\n",
        "        print(\"f1_score = \",f1_score*100)\r\n",
        "        print(\"recall = \",recall*100)\r\n",
        "\r\n",
        "\r\n",
        "    def visualize(self):\r\n",
        "      import matplotlib.pyplot as plt\r\n",
        "      plt.plot(self.loss_history)\r\n",
        "      plt.title('Loss Vs iterations')\r\n",
        "      plt.xlabel('iterations')\r\n",
        "      plt.ylabel('L')\r\n",
        "      plt.show()\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6jxaPMpsAWH"
      },
      "source": [
        "class Data():\r\n",
        "      def shuffle_split_data(self,X,y,train_size=0.7): #X: input data, y:labels, 70% of data for training \r\n",
        "        import numpy as np\r\n",
        "        arr_rand = np.random.rand(X.shape[0]) #shuffles data\r\n",
        "        split = arr_rand < np.percentile(arr_rand, train_size*100) #takes 70% of data\r\n",
        "        X_train =  np.array(X[split]).T #to reshape the data as required for model\r\n",
        "        y_train = np.array(y[split]).ravel() #( m , ) instead of ( m, 1 )\r\n",
        "        X_test = np.array( X[~split]).T #takes the remaining 30% for testing\r\n",
        "        y_test = np.array(y[~split]).ravel() \r\n",
        "        return X_train, y_train, X_test, y_test\r\n",
        "\r\n",
        "      def load_data(self,path,label): \r\n",
        "        import pandas as pd\r\n",
        "        data=pd.read_csv(path) #read the csv data file\r\n",
        "        Y = data[[label]] #getting data labels\r\n",
        "        data.drop([label], inplace=True, axis=1) #dropping the label column\r\n",
        "        X=data\r\n",
        "        return self.shuffle_split_data(X,Y)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcpp1_Kptje1"
      },
      "source": [
        "class utils(): #for saving and loading model\r\n",
        "  def load_model(self,filename):\r\n",
        "    import pickle \r\n",
        "    loaded_model = pickle.load(open(filename, 'rb')) #load the model with the last accuracy achieved\r\n",
        "    return loaded_model\r\n",
        "\r\n",
        "  def save_model(self,nn,filename):\r\n",
        "    import pickle \r\n",
        "    pickle.dump(nn, open(filename, 'wb')) #save the last accuracy achieved model \r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "aR8-2Fv8aVry",
        "outputId": "283e7174-94a5-4ee9-e42a-10e53a37631a"
      },
      "source": [
        "if __name__ == '__main__':\r\n",
        "    # import numpy as np\r\n",
        "    # import pandas as pd\r\n",
        "    # Initialize the NN and build the layers\r\n",
        "    nn = NeuralNetwork(loss='crossentropy', classifier='categorical', learning_rate=.02, metric='accuracy') #instance of class\r\n",
        "    nn.add_layer(units=20, activation='tanh', initializer='xavier') #add layer with desired activation function\r\n",
        "    nn.add_layer(units=40, activation='tanh', initializer='xavier')\r\n",
        "    nn.add_layer(units=10, activation='softmax', initializer='xavier')\r\n",
        "    data_loader=Data() #instance of data class\r\n",
        "    path='/content/drive/MyDrive/datasets/train.csv'\r\n",
        "    label='label'\r\n",
        "    x_train, y_train, x_test, y_test=data_loader.load_data(path,label) #load data\r\n",
        "    nn.train(x_train=x_train, y_train=y_train, iterations=150)\r\n",
        "    nn.visualize()\r\n",
        "    # Test NN on our test set\r\n",
        "    prediction = nn.test(x_test=x_test, y_test=y_test)\r\n",
        "    nn.evaluation_metric(prediction , y_test)\r\n",
        "    util=utils() #instance of utils class\r\n",
        "    filename = 'final_model2.sav' \r\n",
        "    util.save_model(nn,filename) #save model"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training neural network.\n",
            "At iteration 0, J = 2.494353681908836\n",
            "At iteration 1, J = 2.4297375053404866\n",
            "At iteration 2, J = 2.3974168928254023\n",
            "At iteration 3, J = 2.3665485701449103\n",
            "At iteration 4, J = 2.3489138864690786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy =  12.214285714285714\n",
            "precision =  12.214285704591838\n",
            "f1_score =  12.214285709438775\n",
            "recall =  12.214285714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "haw22I3gzbK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c380e2-f13c-426d-f645-9900ad6e966e"
      },
      "source": [
        "x=util.load_model(filename)\r\n",
        "pred=x.test(x_test,y_test)\r\n",
        "x.evaluation_metric(pred,y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy =  12.214285714285714\n",
            "precision =  12.214285704591838\n",
            "f1_score =  12.214285709438775\n",
            "recall =  12.214285714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtOCoW9tBjIx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}